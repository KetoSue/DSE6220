{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8efd322-9399-4dce-a6be-ba76abbfd705",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Tracking Models with MLflow\n",
    "\n",
    "MLflow is pre-installed on the Databricks Runtime for ML. If you are not using the ML Runtime, you will need to install mlflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7ceb6cf-eab3-478c-87f0-107759998090",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "filePath = \"dbfs:/databricks-datasets/learning-spark-v2/sf-airbnb/sf-airbnb-clean.parquet\"\n",
    "airbnbDF = spark.read.parquet(filePath)\n",
    "(trainDF, testDF) = airbnbDF.randomSplit([.8, .2], seed=42)\n",
    "\n",
    "categoricalCols = [field for (field, dataType) in trainDF.dtypes \n",
    "                   if dataType == \"string\"]\n",
    "indexOutputCols = [x + \"Index\" for x in categoricalCols]\n",
    "stringIndexer = StringIndexer(inputCols=categoricalCols, \n",
    "                              outputCols=indexOutputCols, \n",
    "                              handleInvalid=\"skip\")\n",
    "\n",
    "numericCols = [field for (field, dataType) in trainDF.dtypes \n",
    "               if ((dataType == \"double\") & (field != \"price\"))]\n",
    "assemblerInputs = indexOutputCols + numericCols\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs, \n",
    "                               outputCol=\"features\")\n",
    "\n",
    "rf = RandomForestRegressor(labelCol=\"price\", maxBins=40, maxDepth=5, \n",
    "                           numTrees=100, seed=42)\n",
    "\n",
    "pipeline = Pipeline(stages=[stringIndexer, vecAssembler, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e052e26-1e88-41c5-a7d8-f7bef00ddf6a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "729b4168-2249-4af8-bb4a-4ed45bb985f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "import pandas as pd\n",
    "\n",
    "with mlflow.start_run(run_name=\"random-forest\") as run:\n",
    "  # Log params: Num Trees and Max Depth\n",
    "  mlflow.log_param(\"num_trees\", rf.getNumTrees())\n",
    "  mlflow.log_param(\"max_depth\", rf.getMaxDepth())\n",
    " \n",
    "  # Log model\n",
    "  pipelineModel = pipeline.fit(trainDF)\n",
    "  mlflow.spark.log_model(pipelineModel, \"model\")\n",
    "\n",
    "  # Log metrics: RMSE and R2\n",
    "  predDF = pipelineModel.transform(testDF)\n",
    "  regressionEvaluator = RegressionEvaluator(predictionCol=\"prediction\", \n",
    "                                            labelCol=\"price\")\n",
    "  rmse = regressionEvaluator.setMetricName(\"rmse\").evaluate(predDF)\n",
    "  r2 = regressionEvaluator.setMetricName(\"r2\").evaluate(predDF)\n",
    "  mlflow.log_metrics({\"rmse\": rmse, \"r2\": r2})\n",
    "\n",
    "  # Log artifact: Feature Importance Scores\n",
    "  rfModel = pipelineModel.stages[-1]\n",
    "  pandasDF = (pd.DataFrame(list(zip(vecAssembler.getInputCols(), \n",
    "                                    rfModel.featureImportances)), \n",
    "                          columns=[\"feature\", \"importance\"])\n",
    "              .sort_values(by=\"importance\", ascending=False))\n",
    "  # First write to local filesystem, then tell MLflow where to find that file\n",
    "  pandasDF.to_csv(\"/tmp/feature-importance.csv\", index=False)\n",
    "  mlflow.log_artifact(\"/tmp/feature-importance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4d9c2b8-fd42-48ce-8f8a-a3a7dff0ec76",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## MLflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2937f4e-4b61-4d7c-be5d-e16138ccf829",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "runs = client.search_runs(run.info.experiment_id,\n",
    "                          order_by=[\"attributes.start_time desc\"], \n",
    "                          max_results=1)\n",
    "run_id = runs[0].info.run_id\n",
    "runs[0].data.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6fe38d32-cb23-4fa0-9929-85babefd5815",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "%md ## Generate Batch Predictions\n",
    "\n",
    "Let's load the model back in to generate batch predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a654bb1a-aa40-4f57-9935-60a40b694cb1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load saved model with MLflow\n",
    "pipelineModel = mlflow.spark.load_model(f\"runs:/{run_id}/model\")\n",
    "\n",
    "# Generate Predictions\n",
    "inputPath = \"dbfs:/databricks-datasets/learning-spark-v2/sf-airbnb/sf-airbnb-clean.parquet\"\n",
    "inputDF = spark.read.parquet(inputPath)\n",
    "predDF = pipelineModel.transform(inputDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a7674bc-879f-44a7-bacc-c2a37fc6cd42",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Generate Streaming Predictions\n",
    "\n",
    "We can do the same thing to generate streaming predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8769ffb0-8ea0-42e3-8c4a-428dc38bc8cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load saved model with MLflow\n",
    "pipelineModel = mlflow.spark.load_model(f\"runs:/{run_id}/model\")\n",
    "\n",
    "# Set up simulated streaming data\n",
    "repartitionedPath = \"dbfs:/databricks-datasets/learning-spark-v2/sf-airbnb/sf-airbnb-clean-100p.parquet\"\n",
    "schema = spark.read.parquet(repartitionedPath).schema\n",
    "\n",
    "streamingData = (spark\n",
    "                 .readStream\n",
    "                 .schema(schema) # Can set the schema this way\n",
    "                 .option(\"maxFilesPerTrigger\", 1)\n",
    "                 .parquet(repartitionedPath))\n",
    "\n",
    "# Generate Predictions\n",
    "streamPred = pipelineModel.transform(streamingData)\n",
    "\n",
    "# Uncomment the line below to see the streaming predictions\n",
    "# display(streamPred)\n",
    "\n",
    "# Just remember to stop your stream at the end!\n",
    "# streamPred.exit()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "11-1 MLflow",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
